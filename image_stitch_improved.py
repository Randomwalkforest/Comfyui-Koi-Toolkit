from .imagefunc import log, fit_resize_image, tensor2pil, pil2tensor, image2mask
import torch
import numpy as np
import cv2
from PIL import Image


class ImageStitchForICImproved:

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "image_1": ("IMAGE",), 
                "mask_1": ("MASK",),
                "image_2": ("IMAGE",), 
                "mask_2": ("MASK",),
                "direction": (["auto", "top-bottom", "left-right"], {"default": "auto"}),  # å›¾åƒæ‹¼æ¥çš„æ–¹å‘
                "divisible_by": ("INT", {"default": 8, "min": 1, "max": 32, "step": 1}),  # å°ºå¯¸éœ€è¦è¢«æ•´é™¤çš„æ•°å€¼
                "border_ratio": ("FLOAT", {"default": 0.15, "min": 0.0, "max": 1.0, "step": 0.01}),  # è¾¹æ¡†æ‰©å……æ¯”ä¾‹
                "image1_scale_factor": ("FLOAT", {"default": 1.0, "min": 0.1, "max": 5.0, "step": 0.01}),  # image1æ‰‹åŠ¨ç¼©æ”¾ç³»æ•°
                "background_color": (["#FFFFFF", "#000000"], {"default": "#FFFFFF"}),  # èƒŒæ™¯å¡«å……é¢œè‰²
            },
        }

    DESCRIPTION = "æ›´ç²¾ç»†çš„ICæ‹¼æ¥"
    CATEGORY = "ğŸŸKoi-Toolkit"
    FUNCTION = "main"

    RETURN_TYPES = ("IMAGESTITCHFORICIMPROVED_DATA", "IMAGE", "MASK")
    RETURN_NAMES = ("crop_data", "image", "mask")

    def isMaskEmpty(self, mask):
        if mask is None:
            return True
        if torch.all(mask == 0):
            return True
        return False

    def hex_to_rgb(self, hex_color):
        """å°†HEXé¢œè‰²å€¼è½¬æ¢ä¸ºRGBå…ƒç»„ (0-255)"""
        hex_color = hex_color.lstrip('#')
        return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))
    
    def hex_to_rgb_normalized(self, hex_color):
        """å°†HEXé¢œè‰²å€¼è½¬æ¢ä¸ºå½’ä¸€åŒ–çš„RGBå…ƒç»„ (0-1)"""
        r, g, b = self.hex_to_rgb(hex_color)
        return (r / 255.0, g / 255.0, b / 255.0)
    
    def get_padding_value(self, hex_color):
        """è·å–ç”¨äºpaddingçš„é¢œè‰²å€¼ (0-1èŒƒå›´å†…çš„å•ä¸€å€¼ï¼Œç”¨äºç°åº¦æˆ–ç™½è‰²/é»‘è‰²)"""
        r, g, b = self.hex_to_rgb_normalized(hex_color)
        # å¯¹äºç™½è‰²è¿”å›1.0ï¼Œå¯¹äºé»‘è‰²è¿”å›0.0ï¼Œå…¶ä»–é¢œè‰²ä½¿ç”¨äº®åº¦å€¼
        return (r + g + b) / 3.0
    
    def create_canvas(self, height, width, background_color='#FFFFFF'):
        """æ ¹æ®èƒŒæ™¯é¢œè‰²åˆ›å»ºç”»å¸ƒ"""
        r, g, b = self.hex_to_rgb_normalized(background_color)
        canvas = torch.zeros((1, height, width, 3), dtype=torch.float32)
        canvas[:, :, :, 0] = r  # Red channel
        canvas[:, :, :, 1] = g  # Green channel  
        canvas[:, :, :, 2] = b  # Blue channel
        return canvas

    def pil2mask(self, image):
        image_np = np.array(image.convert("L")).astype(np.float32) / 255.0
        mask = torch.from_numpy(image_np)
        return 1.0 - mask

    def fill_mask_holes(self, masks):
        if masks.ndim > 3:
            regions = []
            for mask in masks:
                mask_np = np.clip(255. * mask.cpu().numpy().squeeze(), 0, 255).astype(np.uint8)
                # ä½¿ç”¨OpenCVå¡«å……å­”æ´
                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
                filled_mask = cv2.morphologyEx(mask_np, cv2.MORPH_CLOSE, kernel)
                # è¿›ä¸€æ­¥å¡«å……è¾ƒå¤§çš„å­”æ´
                kernel2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))
                filled_mask = cv2.morphologyEx(filled_mask, cv2.MORPH_CLOSE, kernel2)
                
                # ç›´æ¥è½¬æ¢å›tensorï¼Œé¿å…ä½¿ç”¨pil2maskçš„åè½¬é€»è¾‘
                region_tensor = torch.from_numpy(filled_mask.astype(np.float32) / 255.0).unsqueeze(0).unsqueeze(0)
                regions.append(region_tensor)
            regions_tensor = torch.cat(regions, dim=0)
            return regions_tensor
        else:
            mask_np = np.clip(255. * masks.cpu().numpy().squeeze(), 0, 255).astype(np.uint8)
            # ä½¿ç”¨OpenCVå¡«å……å­”æ´
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
            filled_mask = cv2.morphologyEx(mask_np, cv2.MORPH_CLOSE, kernel)
            # è¿›ä¸€æ­¥å¡«å……è¾ƒå¤§çš„å­”æ´
            kernel2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))
            filled_mask = cv2.morphologyEx(filled_mask, cv2.MORPH_CLOSE, kernel2)
            
            # ç›´æ¥è½¬æ¢å›tensorï¼Œé¿å…ä½¿ç”¨pil2maskçš„åè½¬é€»è¾‘
            region_tensor = torch.from_numpy(filled_mask.astype(np.float32) / 255.0).unsqueeze(0).unsqueeze(0)
            return region_tensor
        
    def fillMask(self, width, height, mask, box=(0, 0), color=0):
        bg = Image.new("L", (width, height), color)  # åˆ›å»ºä¸€ä¸ª 'L' æ¨¡å¼ (ç°åº¦) çš„èƒŒæ™¯
        bg.paste(mask, box, mask)  # å°†é®ç½©ç²˜è´´åˆ°èƒŒæ™¯ä¸Š
        return bg

    def emptyImage(self, width, height, batch_size=1, color=0):
        # åˆ†åˆ«åˆ›å»º R, G, B é€šé“çš„å¼ é‡
        r = torch.full([batch_size, height, width, 1], ((color >> 16) & 0xFF) / 255.0)
        g = torch.full([batch_size, height, width, 1], ((color >> 8) & 0xFF) / 255.0)
        b = torch.full([batch_size, height, width, 1], (color & 0xFF) / 255.0)
        # å°†ä¸‰ä¸ªé€šé“åˆå¹¶æˆä¸€ä¸ªå›¾åƒå¼ é‡
        return torch.cat((r, g, b), dim=-1)

    def resize_image_and_mask(self, image, mask, w, h, background_color='#FFFFFF'):
        ret_images = []
        ret_masks = []
        _mask = Image.new('L', size=(w, h), color='black')
        # ä½¿ç”¨åŠ¨æ€èƒŒæ™¯é¢œè‰²åˆ›å»ºå›¾åƒ
        bg_color = self.hex_to_rgb(background_color)
        _image = Image.new('RGB', size=(w, h), color=bg_color)

        # è°ƒæ•´å›¾åƒå¤§å°
        if image is not None and len(image) > 0:
            for i in image:
                _image = tensor2pil(i).convert('RGB')
                _image = fit_resize_image(_image, w, h, 'fit', Image.LANCZOS, background_color)
                ret_images.append(pil2tensor(_image))

        # è°ƒæ•´é®ç½©å¤§å°
        if mask is not None and len(mask) > 0:
            for m in mask:
                _mask = tensor2pil(m).convert('L')
                _mask = fit_resize_image(_mask, w, h, 'fit', Image.LANCZOS).convert('L')
                ret_masks.append(image2mask(_mask))

        # æ ¹æ®å¤„ç†ç»“æœè¿”å›å¼ é‡
        img_tensor = torch.cat(ret_images, dim=0) if len(ret_images) > 0 else None
        mask_tensor = torch.cat(ret_masks, dim=0) if len(ret_masks) > 0 else None
        return (img_tensor, mask_tensor)

    def main(self, image_1, mask_1, image_2, mask_2, direction, divisible_by, border_ratio, image1_scale_factor, background_color):
        # å¦‚æœmask_2ä¸ºç©ºï¼Œåˆ™ä¸º image_2 åˆ›å»ºä¸€ä¸ªå…¨ç™½é®ç½©
        if self.isMaskEmpty(mask_2):
            mask_2 = torch.full((1, image_2.shape[1], image_2.shape[2]), 1, dtype=torch.float32, device="cpu")

        # è·å–ä¸¤å¼ å›¾çš„å°ºå¯¸
        _, img1_h, img1_w, _ = image_1.shape
        _, img2_h, img2_w, _ = image_2.shape

        # ä¿å­˜image2çš„åŸå§‹å°ºå¯¸ï¼Œç¡®ä¿åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ä¸æ”¹å˜
        orig_img2_h, orig_img2_w = img2_h, img2_w

        # ç¬¬ä¸€æ­¥ï¼šæ ¹æ®mask2çš„éé›¶åŒºåŸŸè°ƒæ•´image1çš„å¤§å°ï¼Œä½†ç¡®ä¿ä¸è¶…è¿‡image2
        if not self.isMaskEmpty(mask_1) and not self.isMaskEmpty(mask_2):
            mask_1 = self.fill_mask_holes(mask_1)
            mask_2 = self.fill_mask_holes(mask_2)
            mask1_area = torch.count_nonzero(mask_1).float()
            mask2_area = torch.count_nonzero(mask_2).float()

            if mask1_area > 0 and mask2_area > 0:
                # è®¡ç®—é¢ç§¯æ¯”ä¾‹çš„å¹³æ–¹æ ¹ä½œä¸ºåˆå§‹ç¼©æ”¾å› å­
                initial_scale_ratio = (mask2_area / mask1_area).sqrt()
                
                # è®¡ç®—åˆå§‹ç¼©æ”¾åçš„å°ºå¯¸
                temp_new_width = round((img1_w * initial_scale_ratio).item())
                temp_new_height = round((img1_h * initial_scale_ratio).item())
                
                # è®¡ç®—æ·»åŠ è¾¹æ¡†åçš„æœ€å¤§å…è®¸å°ºå¯¸ï¼ˆä¸èƒ½è¶…è¿‡image2ï¼‰
                # è€ƒè™‘border_ratioï¼Œè®¡ç®—image1èƒ½è¾¾åˆ°çš„æœ€å¤§å°ºå¯¸
                max_content_w = img2_w / (1 + 2 * border_ratio)  # å‡å»è¾¹æ¡†åçš„æœ€å¤§å†…å®¹å®½åº¦
                max_content_h = img2_h / (1 + 2 * border_ratio)  # å‡å»è¾¹æ¡†åçš„æœ€å¤§å†…å®¹é«˜åº¦
                
                # å¦‚æœæŒ‰maskæ¯”ä¾‹ç¼©æ”¾åä¼šè¶…è¿‡é™åˆ¶ï¼Œåˆ™è¿›è¡Œçº¦æŸ
                if temp_new_width > max_content_w or temp_new_height > max_content_h:
                    # è®¡ç®—å—çº¦æŸçš„ç¼©æ”¾æ¯”ä¾‹
                    width_scale = max_content_w / img1_w
                    height_scale = max_content_h / img1_h
                    constrained_scale = min(width_scale, height_scale, initial_scale_ratio.item())
                    
                    new_width = round(img1_w * constrained_scale)
                    new_height = round(img1_h * constrained_scale)
                    
                else:
                    new_width = temp_new_width
                    new_height = temp_new_height
                    log(f"Using mask-based scale ratio: {initial_scale_ratio:.3f}")

                if new_width > 0 and new_height > 0:
                    image_1, mask_1 = self.resize_image_and_mask(image_1, mask_1, new_width, new_height, background_color)
                    # æ›´æ–° image_1 å°ºå¯¸
                    _, img1_h, img1_w, _ = image_1.shape

        # ç¬¬1.5æ­¥ï¼šåº”ç”¨ç”¨æˆ·æ‰‹åŠ¨ç¼©æ”¾å› å­ï¼ˆåœ¨maskåŒ¹é…ä¹‹åï¼Œçº¦æŸè®¡ç®—ä¹‹å‰ï¼‰
        if image1_scale_factor != 1.0:
            # è®¡ç®—æ‰‹åŠ¨ç¼©æ”¾åçš„æ–°å°ºå¯¸
            manual_new_width = round(img1_w * image1_scale_factor)
            manual_new_height = round(img1_h * image1_scale_factor)
            
            if manual_new_width > 0 and manual_new_height > 0:
                image_1, mask_1 = self.resize_image_and_mask(image_1, mask_1, manual_new_width, manual_new_height, background_color)
                # æ›´æ–° image_1 å°ºå¯¸
                _, img1_h, img1_w, _ = image_1.shape
                log(f"Applied manual scale factor {image1_scale_factor:.2f}: resized image1 to {manual_new_width}x{manual_new_height}")

        # ç¬¬äºŒæ­¥ï¼šè®¡ç®—æ·»åŠ è¾¹æ¡†åçš„image1å°ºå¯¸ï¼Œç¡®ä¿ä¸è¶…è¿‡image2
        # è®¡ç®—æŒ‡å®šæ¯”ä¾‹çš„æœ€å°è¾¹æ¡†å¤§å°
        min_border_h = int(img1_h * border_ratio)
        min_border_w = int(img1_w * border_ratio)
        
        # è®¡ç®—åŠ ä¸Šæœ€å°è¾¹æ¡†åçš„ä¸´æ—¶å°ºå¯¸
        temp_h = img1_h + 2 * min_border_h
        temp_w = img1_w + 2 * min_border_w
        
        # è®¡ç®—èƒ½è¢«æŒ‡å®šæ•°å€¼æ•´é™¤çš„æœ€ç»ˆç›®æ ‡å°ºå¯¸ï¼ˆå‘ä¸Šå–æ•´ï¼‰
        target_h = ((temp_h + divisible_by - 1) // divisible_by) * divisible_by
        target_w = ((temp_w + divisible_by - 1) // divisible_by) * divisible_by
        
        # æœ€ç»ˆå®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿ä¸è¶…è¿‡image2çš„å°ºå¯¸
        expanded_img1_h = min(target_h, img2_h)
        expanded_img1_w = min(target_w, img2_w)
        
        # å¦‚æœè¢«é™åˆ¶äº†ï¼Œè®°å½•æ—¥å¿—
        if expanded_img1_h < target_h or expanded_img1_w < target_w:
            log(f"Final size constrained: target {target_w}x{target_h} limited to {expanded_img1_w}x{expanded_img1_h} to not exceed image2")
        
        log(f"Final image1 with border: {expanded_img1_w}x{expanded_img1_h}, image2: {img2_w}x{img2_h}")

        # ç¬¬ä¸‰æ­¥ï¼šå¦‚æœ direction æ˜¯ 'auto'ï¼ŒåŸºäº"æœ€è¿‘ä¼¼æ­£æ–¹å½¢æ³•åˆ™"é€‰æ‹©æ‹¼æ¥æ–¹å‘
        if direction == 'auto':
            # å·¦å³æ‹¼æ¥ï¼šimage1åœ¨å·¦ï¼Œimage2åœ¨å³
            # é«˜åº¦å–æœ€å¤§å€¼ï¼Œå®½åº¦ç›¸åŠ 
            final_h_lr = max(expanded_img1_h, img2_h)
            final_w_lr = expanded_img1_w + img2_w
            aspect_ratio_lr = final_w_lr / final_h_lr
            
            # ä¸Šä¸‹æ‹¼æ¥ï¼šimage1åœ¨ä¸Šï¼Œimage2åœ¨ä¸‹
            # å®½åº¦å–æœ€å¤§å€¼ï¼Œé«˜åº¦ç›¸åŠ 
            final_h_tb = expanded_img1_h + img2_h
            final_w_tb = max(expanded_img1_w, img2_w)
            aspect_ratio_tb = final_w_tb / final_h_tb
            
            # è®¡ç®—è·ç¦»æ­£æ–¹å½¢(1:1)çš„åå·®
            # ä½¿ç”¨å¯¹æ•°æ¥å¤„ç†å¤§äº1å’Œå°äº1çš„æ¯”ä¾‹ï¼Œä½¿å…¶å¯¹ç§°
            lr_deviation = abs(aspect_ratio_lr - 1.0) if aspect_ratio_lr >= 1.0 else abs(1.0 / aspect_ratio_lr - 1.0)
            tb_deviation = abs(aspect_ratio_tb - 1.0) if aspect_ratio_tb >= 1.0 else abs(1.0 / aspect_ratio_tb - 1.0)
            
            # é€‰æ‹©æ›´æ¥è¿‘æ­£æ–¹å½¢çš„æ–¹å‘ï¼ˆåå·®æ›´å°çš„ï¼‰
            direction = 'left-right' if lr_deviation <= tb_deviation else 'top-bottom'
            
        # ç¬¬å››æ­¥ï¼šä¸ºimage1æ·»åŠ è¾¹æ¡†
        # è®¡ç®—å®é™…éœ€è¦çš„æ€»padding
        total_pad_h = expanded_img1_h - img1_h
        total_pad_w = expanded_img1_w - img1_w
        
        # å¹³å‡åˆ†é…åˆ°å„è¾¹
        pad_top = total_pad_h // 2
        pad_bottom = total_pad_h - pad_top
        pad_left = total_pad_w // 2
        pad_right = total_pad_w - pad_left
        
        # åº”ç”¨paddingåˆ°image1ï¼Œä½¿ç”¨åŠ¨æ€èƒŒæ™¯é¢œè‰²
        # ä¸ºRGBä¸‰ä¸ªé€šé“åˆ†åˆ«åˆ›å»ºpaddingåçš„å›¾åƒ
        r, g, b = self.hex_to_rgb_normalized(background_color)
        
        # åˆ†åˆ«ä¸ºæ¯ä¸ªé€šé“åº”ç”¨padding
        img_padding = (0, 0, pad_left, pad_right, pad_top, pad_bottom)
        image_1_r = torch.nn.functional.pad(image_1[:, :, :, 0:1], img_padding, "constant", r)
        image_1_g = torch.nn.functional.pad(image_1[:, :, :, 1:2], img_padding, "constant", g)
        image_1_b = torch.nn.functional.pad(image_1[:, :, :, 2:3], img_padding, "constant", b)
        
        # é‡æ–°ç»„åˆRGBé€šé“
        image_1 = torch.cat([image_1_r, image_1_g, image_1_b], dim=-1)
        
        # åŒæ­¥paddingåˆ°mask1
        if not self.isMaskEmpty(mask_1):
            mask_padding = (pad_left, pad_right, pad_top, pad_bottom)
            mask_1 = torch.nn.functional.pad(mask_1, mask_padding, "constant", 0.0)

        # ç¬¬äº”æ­¥ï¼šæ‰§è¡Œæ‹¼æ¥
        # æ›´æ–°image1çš„å°ºå¯¸ï¼ˆæ·»åŠ è¾¹æ¡†åï¼‰
        _, img1_h, img1_w, _ = image_1.shape
        
        # æ ¹æ®æ‹¼æ¥æ–¹å‘åˆ›å»ºæœ€ç»ˆç”»å¸ƒ
        if direction == 'left-right':
            # å·¦å³æ‹¼æ¥ï¼šimage1åœ¨å·¦ï¼Œimage2åœ¨å³
            final_h = max(img1_h, img2_h)
            final_w = img1_w + img2_w
            
            # åˆ›å»ºæŒ‡å®šé¢œè‰²çš„ç”»å¸ƒ
            canvas = self.create_canvas(final_h, final_w, background_color)
            
            # æ”¾ç½®image1ï¼ˆå·¦ä¾§ï¼Œå‚ç›´å±…ä¸­ï¼‰
            y1_offset = (final_h - img1_h) // 2
            canvas[:, y1_offset:y1_offset+img1_h, 0:img1_w, :] = image_1
            
            # æ”¾ç½®image2ï¼ˆå³ä¾§ï¼Œå‚ç›´å±…ä¸­ï¼‰
            y2_offset = (final_h - img2_h) // 2
            canvas[:, y2_offset:y2_offset+img2_h, img1_w:img1_w+img2_w, :] = image_2
            
            # åˆ›å»ºmaskï¼ˆåªåœ¨image2çš„ä½ç½®ï¼‰
            mask = torch.zeros((1, final_h, final_w), dtype=torch.float32)
            mask[:, y2_offset:y2_offset+img2_h, img1_w:img1_w+img2_w] = mask_2
            
            # è®°å½•image2åœ¨ç”»å¸ƒä¸­çš„ä½ç½®
            x2_pos = img1_w
            y2_pos = y2_offset
            
        else:  # top-bottom
            # ä¸Šä¸‹æ‹¼æ¥ï¼šimage1åœ¨ä¸Šï¼Œimage2åœ¨ä¸‹
            final_h = img1_h + img2_h
            final_w = max(img1_w, img2_w)
            
            # åˆ›å»ºæŒ‡å®šé¢œè‰²çš„ç”»å¸ƒ
            canvas = self.create_canvas(final_h, final_w, background_color)
            
            # æ”¾ç½®image1ï¼ˆé¡¶éƒ¨ï¼Œæ°´å¹³å±…ä¸­ï¼‰
            x1_offset = (final_w - img1_w) // 2
            canvas[:, 0:img1_h, x1_offset:x1_offset+img1_w, :] = image_1
            
            # æ”¾ç½®image2ï¼ˆåº•éƒ¨ï¼Œæ°´å¹³å±…ä¸­ï¼‰
            x2_offset = (final_w - img2_w) // 2
            canvas[:, img1_h:img1_h+img2_h, x2_offset:x2_offset+img2_w, :] = image_2
            
            # åˆ›å»ºmaskï¼ˆåªåœ¨image2çš„ä½ç½®ï¼‰
            mask = torch.zeros((1, final_h, final_w), dtype=torch.float32)
            mask[:, img1_h:img1_h+img2_h, x2_offset:x2_offset+img2_w] = mask_2
            
            # è®°å½•image2åœ¨ç”»å¸ƒä¸­çš„ä½ç½®
            x2_pos = x2_offset
            y2_pos = img1_h



        # åˆ›å»ºç²¾ç»†æ‹¼æ¥ IC æ•°æ®åŒ…
        image_stitch_data = ImageStitchForICImproved_Data(
            width=orig_img2_w,   # åŸå§‹image2å®½åº¦
            height=orig_img2_h,  # åŸå§‹image2é«˜åº¦
            x_offset=x2_pos,     # image2åœ¨ç”»å¸ƒä¸­çš„xåæ ‡
            y_offset=y2_pos,     # image2åœ¨ç”»å¸ƒä¸­çš„yåæ ‡
            orig_width=orig_img2_w,   # åŸå§‹ image_2 çš„å®½åº¦
            orig_height=orig_img2_h   # åŸå§‹ image_2 çš„é«˜åº¦
        )
        
        # è¿”å›æ‰€æœ‰ç»“æœ
        return (image_stitch_data, canvas, mask)



class ImageStitchForICImproved_Data:

    def __init__(self, width, height, x_offset, y_offset, orig_width, orig_height):
        self.width = width                # ç›®æ ‡åŒºåŸŸå®½åº¦
        self.height = height              # ç›®æ ‡åŒºåŸŸé«˜åº¦
        self.x_offset = x_offset          # Xåç§»é‡
        self.y_offset = y_offset          # Yåç§»é‡
        self.orig_width = orig_width      # åŸå§‹å›¾åƒå®½åº¦
        self.orig_height = orig_height    # åŸå§‹å›¾åƒé«˜åº¦



class ImageStitchForICImproved_CropBack:

    def __init__(self):
        self.NODE_NAME = 'imageStitchForICImproved_CropBack'

    def crop_and_scale_as(self, image: Image, size: tuple):
        target_width, target_height = size
        ret_image = fit_resize_image(image, target_width, target_height, "crop", Image.LANCZOS)
        return ret_image
    
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "crop_data": ("IMAGESTITCHFORICIMPROVED_DATA",),
                "image": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    FUNCTION = "crop_back"
    CATEGORY = "ğŸŸKoi-Toolkit"

    def crop_back(self, image, crop_data):
        # è·å–è£åˆ‡å‚æ•°
        width = crop_data.width
        height = crop_data.height
        x = crop_data.x_offset
        y = crop_data.y_offset
        orig_width = crop_data.orig_width
        orig_height = crop_data.orig_height
        
        # ç¡®ä¿åæ ‡ä¸è¶…å‡ºå›¾åƒè¾¹ç•Œ
        x = min(x, image.shape[2] - 1)
        y = min(y, image.shape[1] - 1)
        to_x = width + x
        to_y = height + y
        
        # è£åˆ‡å›¾åƒçš„ç›®æ ‡åŒºåŸŸ
        img = image[:, y:to_y, x:to_x, :]
        
        # è½¬æ¢ä¸ºPILå›¾åƒ
        pil_image = tensor2pil(img)
        
        # ä½¿ç”¨crop_and_scale_aså‡½æ•°è°ƒæ•´åˆ°åŸå§‹å°ºå¯¸
        ret_image = self.crop_and_scale_as(pil_image, (orig_width, orig_height))
        
        return (pil2tensor(ret_image),)




NODE_CLASS_MAPPINGS = {
    "imageStitchForICImproved": ImageStitchForICImproved,
    "imageStitchForICImproved_CropBack": ImageStitchForICImproved_CropBack,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "imageStitchForICImproved": "ğŸŸImage Stitch For IC Improved",
    "imageStitchForICImproved_CropBack": "ğŸŸImage Stitch For IC Improved CropBack",
}