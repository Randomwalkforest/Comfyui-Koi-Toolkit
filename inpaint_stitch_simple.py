import torch
import torchvision.transforms.functional as F
from PIL import Image


def rescale_i(samples, width, height, algorithm: str):
    """è°ƒæ•´å›¾åƒå¤§å°çš„è¾…åŠ©å‡½æ•°"""
    samples = samples.movedim(-1, 1)
    algorithm = getattr(Image, algorithm.upper())  # ä¾‹å¦‚ Image.BICUBIC
    samples_pil: Image.Image = F.to_pil_image(samples[0].cpu()).resize((width, height), algorithm)
    samples = F.to_tensor(samples_pil).unsqueeze(0)
    samples = samples.movedim(1, -1)
    return samples


def stitch_simple(canvas_image, new_image, ctc_x, ctc_y, ctc_w, ctc_h, cto_x, cto_y, cto_w, cto_h, downscale_algorithm, upscale_algorithm):
    """
    ç®€åŒ–ç‰ˆçš„å›¾åƒæ‹¼æ¥å‡½æ•°ï¼Œç›´æ¥å°†æ–°å›¾åƒæ‹¼æ¥åˆ°ç”»å¸ƒä¸Šï¼Œä¸ä½¿ç”¨é®ç½©æ··åˆ
    """
    canvas_image = canvas_image.clone()
    new_image = new_image.clone()
    
    # è°ƒæ•´æ–°å›¾åƒå¤§å°ä»¥åŒ¹é…ç›®æ ‡åŒºåŸŸ
    _, h, w, _ = new_image.shape
    if ctc_w > w or ctc_h > h:  # éœ€è¦æ”¾å¤§
        resized_image = rescale_i(new_image, ctc_w, ctc_h, upscale_algorithm)
    else:  # éœ€è¦ç¼©å°
        resized_image = rescale_i(new_image, ctc_w, ctc_h, downscale_algorithm)
    
    # ç›´æ¥å°†è°ƒæ•´å¤§å°åçš„å›¾åƒç²˜è´´åˆ°ç”»å¸ƒä¸Š
    canvas_image[:, ctc_y:ctc_y + ctc_h, ctc_x:ctc_x + ctc_w] = resized_image
    
    # è£å‰ªå›åŸå§‹å›¾åƒåŒºåŸŸ
    output_image = canvas_image[:, cto_y:cto_y + cto_h, cto_x:cto_x + cto_w]
    
    return output_image


class SimpleImageStitch:
    """
    ç®€åŒ–ç‰ˆå›¾åƒæ‹¼æ¥èŠ‚ç‚¹
    
    æ¥æ”¶stitcherå¯¹è±¡å’Œæ–°å›¾åƒï¼Œå°†æ–°å›¾åƒç›´æ¥æ‹¼æ¥åˆ°åŸå§‹ä½ç½®ï¼Œä¸è¿›è¡Œé®ç½©æ··åˆ
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "stitcher": ("STITCHER",),
                "new_image": ("IMAGE",),
            }
        }
    
    CATEGORY = "ğŸŸKoi-Toolkit"
    DESCRIPTION = "å°†æ–°å›¾åƒç›´æ¥æ‹¼æ¥å›åŸå§‹ä½ç½®ï¼Œä¸ä½¿ç”¨é®ç½©æ··åˆ"
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    
    FUNCTION = "stitch_simple_image"
    
    def stitch_simple_image(self, stitcher, new_image):
        new_image = new_image.clone()
        results = []
        
        batch_size = new_image.shape[0]
        assert len(stitcher['cropped_to_canvas_x']) == batch_size or len(stitcher['cropped_to_canvas_x']) == 1, \
            "Stitch batch size doesn't match image batch size"
        
        override = False
        if len(stitcher['cropped_to_canvas_x']) != batch_size and len(stitcher['cropped_to_canvas_x']) == 1:
            override = True
        
        for b in range(batch_size):
            one_image = new_image[b]
            one_stitcher = {}
            
            # å¤åˆ¶ç®—æ³•å‚æ•°
            for key in ['downscale_algorithm', 'upscale_algorithm']:
                one_stitcher[key] = stitcher[key]
            
            # å¤åˆ¶åæ ‡å’Œå›¾åƒæ•°æ®
            for key in ['canvas_to_orig_x', 'canvas_to_orig_y', 'canvas_to_orig_w', 'canvas_to_orig_h', 
                       'canvas_image', 'cropped_to_canvas_x', 'cropped_to_canvas_y', 
                       'cropped_to_canvas_w', 'cropped_to_canvas_h']:
                if override:  # ä¸€ä¸ªstitcherç”¨äºå¤šå¼ å›¾åƒ
                    one_stitcher[key] = stitcher[key][0]
                else:
                    one_stitcher[key] = stitcher[key][b]
            
            one_image = one_image.unsqueeze(0)
            one_image = self.stitch_single_image(one_stitcher, one_image)
            one_image = one_image.squeeze(0)
            one_image = one_image.clone()
            results.append(one_image)
        
        result_batch = torch.stack(results, dim=0)
        
        return (result_batch,)
    
    def stitch_single_image(self, stitcher, new_image):
        downscale_algorithm = stitcher['downscale_algorithm']
        upscale_algorithm = stitcher['upscale_algorithm']
        canvas_image = stitcher['canvas_image']
        
        ctc_x = stitcher['cropped_to_canvas_x']
        ctc_y = stitcher['cropped_to_canvas_y']
        ctc_w = stitcher['cropped_to_canvas_w']
        ctc_h = stitcher['cropped_to_canvas_h']
        
        cto_x = stitcher['canvas_to_orig_x']
        cto_y = stitcher['canvas_to_orig_y']
        cto_w = stitcher['canvas_to_orig_w']
        cto_h = stitcher['canvas_to_orig_h']
        
        output_image = stitch_simple(canvas_image, new_image, ctc_x, ctc_y, ctc_w, ctc_h, 
                                   cto_x, cto_y, cto_w, cto_h, downscale_algorithm, upscale_algorithm)
        
        return output_image


NODE_CLASS_MAPPINGS = {
    "SimpleImageStitch": SimpleImageStitch,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "SimpleImageStitch": "ğŸŸ Simple Image Stitch",
}
