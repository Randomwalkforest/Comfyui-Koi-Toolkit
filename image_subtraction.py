import torch
import numpy as np

class ImageSubtraction:
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image_a": ("IMAGE",),
                "image_b": ("IMAGE",),
                "mode": (["absolute_diff", "signed_diff", "threshold_diff"], {"default": "absolute_diff"}),
                "threshold": ("FLOAT", {"default": 0.1, "min": 0.0, "max": 1.0, "step": 0.01}),
                "normalize": ("BOOLEAN", {"default": True}),
            }
        }
    
    RETURN_TYPES = ("MASK", "IMAGE")
    RETURN_NAMES = ("diff_mask", "diff_image")
    FUNCTION = "subtract_images"
    CATEGORY = "ğŸŸKoi-Toolkit"
    
    def subtract_images(self, image_a, image_b, mode="absolute_diff", threshold=0.1, normalize=True):
        """
        è®¡ç®—ä¸¤å¼ å›¾ç‰‡çš„å·®å¼‚
        
        å‚æ•°:
        - image_a: ç¬¬ä¸€å¼ å›¾ç‰‡ (ComfyUI IMAGEæ ¼å¼)
        - image_b: ç¬¬äºŒå¼ å›¾ç‰‡ (ComfyUI IMAGEæ ¼å¼) 
        - mode: å·®å¼‚è®¡ç®—æ¨¡å¼
        - threshold: é˜ˆå€¼åŒ–æ¨¡å¼ä¸‹çš„é˜ˆå€¼
        - normalize: æ˜¯å¦å½’ä¸€åŒ–è¾“å‡º
        """
        
        # ç¡®ä¿ä¸¤å¼ å›¾ç‰‡å°ºå¯¸ç›¸åŒ
        if image_a.shape != image_b.shape:
            # è°ƒæ•´image_bçš„å°ºå¯¸åŒ¹é…image_a
            batch_size, height, width, channels = image_a.shape
            image_b = torch.nn.functional.interpolate(
                image_b.permute(0, 3, 1, 2), 
                size=(height, width), 
                mode='bilinear', 
                align_corners=False
            ).permute(0, 2, 3, 1)
        
        # è½¬æ¢ä¸ºç°åº¦å›¾è¿›è¡Œå·®å¼‚è®¡ç®—ï¼ˆä½¿ç”¨æ ‡å‡†RGBåˆ°ç°åº¦çš„æƒé‡ï¼‰
        def rgb_to_gray(img):
            return 0.299 * img[..., 0] + 0.587 * img[..., 1] + 0.114 * img[..., 2]
        
        gray_a = rgb_to_gray(image_a)
        gray_b = rgb_to_gray(image_b)
        
        # æ ¹æ®æ¨¡å¼è®¡ç®—å·®å¼‚
        if mode == "absolute_diff":
            # ç»å¯¹å·®å¼‚
            diff = torch.abs(gray_a - gray_b)
        elif mode == "signed_diff":
            # æœ‰ç¬¦å·å·®å¼‚ (A - B)
            diff = gray_a - gray_b
            # å°†èŒƒå›´ä»[-1,1]æ˜ å°„åˆ°[0,1]
            diff = (diff + 1.0) / 2.0
        elif mode == "threshold_diff":
            # é˜ˆå€¼åŒ–å·®å¼‚
            abs_diff = torch.abs(gray_a - gray_b)
            diff = (abs_diff > threshold).float()
        else:
            diff = torch.abs(gray_a - gray_b)
        
        # å½’ä¸€åŒ–åˆ°[0,1]èŒƒå›´
        if normalize and mode != "threshold_diff":
            diff_min = diff.min()
            diff_max = diff.max()
            if diff_max > diff_min:
                diff = (diff - diff_min) / (diff_max - diff_min)
        
        # ç¡®ä¿å€¼åœ¨[0,1]èŒƒå›´å†…
        diff = torch.clamp(diff, 0.0, 1.0)
        
        # åˆ›å»ºå½©è‰²å·®å¼‚å›¾åƒï¼ˆå°†ç°åº¦å·®å¼‚å¤åˆ¶åˆ°RGBä¸‰ä¸ªé€šé“ï¼‰
        diff_image = diff.unsqueeze(-1).repeat(1, 1, 1, 3)
        
        return (diff, diff_image)


class ImageSubtractionAdvanced:
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image_a": ("IMAGE",),
                "image_b": ("IMAGE",),
                "method": (["L1", "L2", "SSIM", "per_channel"], {"default": "L1"}),
                "output_format": (["mask_only", "heatmap", "both"], {"default": "both"}),
            },
            "optional": {
                "blur_sigma": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 5.0, "step": 0.1}),
                "gamma_correction": ("FLOAT", {"default": 1.0, "min": 0.1, "max": 3.0, "step": 0.1}),
            }
        }
    
    RETURN_TYPES = ("MASK", "IMAGE", "IMAGE")
    RETURN_NAMES = ("diff_mask", "diff_heatmap", "overlay")
    FUNCTION = "advanced_subtract"
    CATEGORY = "ğŸŸKoi-Toolkit"
    
    def advanced_subtract(self, image_a, image_b, method="L1", output_format="both", 
                         blur_sigma=0.0, gamma_correction=1.0):
        """
        é«˜çº§å·®å¼‚è®¡ç®—
        """
        
        # ç¡®ä¿å°ºå¯¸åŒ¹é…
        if image_a.shape != image_b.shape:
            batch_size, height, width, channels = image_a.shape
            image_b = torch.nn.functional.interpolate(
                image_b.permute(0, 3, 1, 2), 
                size=(height, width), 
                mode='bilinear', 
                align_corners=False
            ).permute(0, 2, 3, 1)
        
        # åº”ç”¨é«˜æ–¯æ¨¡ç³Šï¼ˆå¦‚æœéœ€è¦ï¼‰
        if blur_sigma > 0:
            from torch.nn.functional import conv2d
            # åˆ›å»ºé«˜æ–¯æ ¸
            kernel_size = int(6 * blur_sigma + 1)
            if kernel_size % 2 == 0:
                kernel_size += 1
            
            x = torch.arange(kernel_size, dtype=torch.float32) - kernel_size // 2
            gaussian_1d = torch.exp(-x**2 / (2 * blur_sigma**2))
            gaussian_1d = gaussian_1d / gaussian_1d.sum()
            
            gaussian_2d = gaussian_1d[:, None] * gaussian_1d[None, :]
            gaussian_2d = gaussian_2d[None, None, :, :]
            
            # å¯¹æ¯ä¸ªé€šé“åº”ç”¨æ¨¡ç³Š
            for i in range(3):
                image_a[:, :, :, i:i+1] = conv2d(
                    image_a[:, :, :, i:i+1].permute(0, 3, 1, 2),
                    gaussian_2d,
                    padding=kernel_size//2
                ).permute(0, 2, 3, 1)
                
                image_b[:, :, :, i:i+1] = conv2d(
                    image_b[:, :, :, i:i+1].permute(0, 3, 1, 2),
                    gaussian_2d,
                    padding=kernel_size//2
                ).permute(0, 2, 3, 1)
        
        # æ ¹æ®æ–¹æ³•è®¡ç®—å·®å¼‚
        if method == "L1":
            diff = torch.mean(torch.abs(image_a - image_b), dim=-1)
        elif method == "L2":
            diff = torch.sqrt(torch.mean((image_a - image_b)**2, dim=-1))
        elif method == "per_channel":
            # åˆ†é€šé“è®¡ç®—å·®å¼‚å¹¶å–æœ€å¤§å€¼
            channel_diffs = torch.abs(image_a - image_b)
            diff = torch.max(channel_diffs, dim=-1)[0]
        else:  # SSIMéœ€è¦æ›´å¤æ‚çš„å®ç°ï¼Œè¿™é‡Œç”¨ç®€åŒ–ç‰ˆæœ¬
            diff = torch.mean(torch.abs(image_a - image_b), dim=-1)
        
        # åº”ç”¨ä¼½é©¬æ ¡æ­£
        if gamma_correction != 1.0:
            diff = torch.pow(diff, gamma_correction)
        
        # å½’ä¸€åŒ–
        diff_min = diff.min()
        diff_max = diff.max()
        if diff_max > diff_min:
            diff = (diff - diff_min) / (diff_max - diff_min)
        
        diff = torch.clamp(diff, 0.0, 1.0)
        
        # åˆ›å»ºçƒ­åŠ›å›¾ï¼ˆçº¢è‰²è¡¨ç¤ºå·®å¼‚å¤§çš„åŒºåŸŸï¼‰
        heatmap = torch.zeros_like(image_a)
        heatmap[..., 0] = diff  # çº¢è‰²é€šé“
        heatmap[..., 1] = 1.0 - diff  # ç»¿è‰²é€šé“ï¼ˆå·®å¼‚å°çš„åœ°æ–¹ä¸ºç»¿è‰²ï¼‰
        heatmap[..., 2] = 1.0 - diff  # è“è‰²é€šé“
        
        # åˆ›å»ºå åŠ å›¾åƒ
        overlay = 0.7 * image_a + 0.3 * heatmap
        overlay = torch.clamp(overlay, 0.0, 1.0)
        
        return (diff, heatmap, overlay)


# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ImageSubtraction": ImageSubtraction,
    "ImageSubtractionAdvanced": ImageSubtractionAdvanced,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ImageSubtraction": "ğŸŸ Image Subtraction",
    "ImageSubtractionAdvanced": "ğŸŸ Image Subtraction Advanced",
}
